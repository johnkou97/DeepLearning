{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "T-VUeHgT_Lxn",
    "outputId": "bcad4002-21c5-45c7-e81b-f550ab029ddf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 17:03:00.886575: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-25 17:03:00.954454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 17:03:00.960033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 17:03:00.960194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 17:03:01.423695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 17:03:01.423922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 17:03:01.424067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 17:03:01.424169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 6147 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fL9d1FpFDCJY",
    "outputId": "a17967f0-7721-439f-dcba-b46de1237914"
   },
   "outputs": [],
   "source": [
    "# !wget 'https://surfdrive.surf.nl/files/index.php/s/B8emtQRGUeAaqmz/download'\n",
    "\n",
    "# !mv download a2_data.zip\n",
    "\n",
    "# !yes | unzip a2_data.zip\n",
    "\n",
    "# !rm a2_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdciyQQVBDBm",
    "outputId": "13c32364-18cb-4d5d-ead2-6755a4a6973e"
   },
   "outputs": [],
   "source": [
    "images = np.load(\"images.npy\")\n",
    "labels = np.load(\"labels.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oXcc25WBBclr"
   },
   "outputs": [],
   "source": [
    "# Randomize and split data\n",
    "p = np.random.RandomState(seed=42).permutation(len(labels))\n",
    "images = images[p]\n",
    "labels = labels[p]\n",
    "\n",
    "#images = np.expand_dims(images, axis=-1)\n",
    "\n",
    "images = images.astype('float32')\n",
    "images /= 255\n",
    "\n",
    "split_idx = int(len(images)*0.8)\n",
    "\n",
    "#print(labels[5432:5472])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5L3fwqgGlaG",
    "outputId": "88feed02-3260-4a9a-e295-40eb57d72432"
   },
   "outputs": [],
   "source": [
    "# Regression\n",
    "reg_labels = np.zeros(len(images))\n",
    "reg_labels = labels[:, 0] + labels[:, 1]/60.0\n",
    "\n",
    "train_images = images[:split_idx]\n",
    "train_labels = labels[:split_idx]\n",
    "\n",
    "test_images = images[split_idx:]\n",
    "test_labels = labels[split_idx:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the common sense accuracy. The class is to be used as a loss function for training, while the clock_loss_np is for evaluating the accuracy after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qQ_2YibMBCcQ"
   },
   "outputs": [],
   "source": [
    "class ClockLossAccuracy(tf.keras.losses.Loss):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "  '''def call2(self, y_true, y_pred):\n",
    "    mse = tf.reduce_mean(tf.square(y_pred-y_true))\n",
    "    rmse = tf.math.sqrt(mse)\n",
    "    return rmse / tf.reduce_mean(tf.square(y_true)) - 1'''\n",
    "\n",
    "  def call(self, y_true, y_pred):\n",
    "    y_pred = y_pred % 12.0\n",
    "    res = tf.math.abs(y_true - y_pred)\n",
    "    #tf.print(res)\n",
    "    res2 = tf.math.minimum(res, 12.0 - res)\n",
    "    #tf.print(res2)\n",
    "    res3 = tf.square(res2)\n",
    "    return tf.reduce_mean(res3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DRCwOg8bTHyH"
   },
   "outputs": [],
   "source": [
    "def clock_loss_np(y_true, y_pred):\n",
    "    res = np.abs(y_true - y_pred)\n",
    "    res = np.minimum(res, 12.0 - res)\n",
    "    return np.mean(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MeanSquaredError as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TKSywk66Gr8d",
    "outputId": "cf69e1bf-b44e-48bf-c644-e51e67fb4177"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 15:55:47.235052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 15:55:47.235218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 15:55:47.235318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 15:55:47.235550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 15:55:47.235658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 15:55:47.235755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 15:55:47.235899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 15:55:47.236002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 15:55:47.236083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6147 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2022-11-25 15:55:47.351434: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n",
      "2022-11-25 15:55:47.824396: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 15:55:49.448939: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "2022-11-25 15:55:50.093191: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 15:55:50.095288: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 15:55:50.095312: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-11-25 15:55:50.095790: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 15:55:50.095911: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-11-25 15:55:50.692121: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 6s 22ms/step - loss: 14.5999 - mae: 3.2151 - val_loss: 12.3529 - val_mae: 3.0259\n",
      "Epoch 2/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 12.7276 - mae: 3.0168 - val_loss: 12.7785 - val_mae: 2.9756\n",
      "Epoch 3/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 11.0661 - mae: 2.7380 - val_loss: 10.5189 - val_mae: 2.6055\n",
      "Epoch 4/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 10.1524 - mae: 2.5755 - val_loss: 9.4124 - val_mae: 2.4717\n",
      "Epoch 5/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 9.6014 - mae: 2.4916 - val_loss: 8.9378 - val_mae: 2.3637\n",
      "Epoch 6/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 8.7762 - mae: 2.3649 - val_loss: 8.0088 - val_mae: 2.2354\n",
      "Epoch 7/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 8.0708 - mae: 2.2484 - val_loss: 7.5643 - val_mae: 2.1439\n",
      "Epoch 8/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 7.2644 - mae: 2.1005 - val_loss: 7.5955 - val_mae: 2.1250\n",
      "Epoch 9/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 6.6153 - mae: 1.9809 - val_loss: 7.6107 - val_mae: 2.1895\n",
      "Epoch 10/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 5.9561 - mae: 1.8612 - val_loss: 6.2323 - val_mae: 1.8830\n",
      "Epoch 11/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 5.3984 - mae: 1.7663 - val_loss: 5.5061 - val_mae: 1.7326\n",
      "Epoch 12/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 4.7821 - mae: 1.6524 - val_loss: 4.9150 - val_mae: 1.6192\n",
      "Epoch 13/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 4.3300 - mae: 1.5587 - val_loss: 5.3010 - val_mae: 1.6466\n",
      "Epoch 14/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 3.8082 - mae: 1.4640 - val_loss: 4.2540 - val_mae: 1.4857\n",
      "Epoch 15/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 3.4685 - mae: 1.3996 - val_loss: 4.8311 - val_mae: 1.6127\n",
      "Epoch 16/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 3.1041 - mae: 1.3174 - val_loss: 4.8898 - val_mae: 1.6291\n",
      "Epoch 17/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 2.7070 - mae: 1.2280 - val_loss: 3.9914 - val_mae: 1.4199\n",
      "Epoch 18/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 2.4116 - mae: 1.1572 - val_loss: 3.7765 - val_mae: 1.4076\n",
      "Epoch 19/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 2.1128 - mae: 1.0825 - val_loss: 3.4954 - val_mae: 1.2733\n",
      "Epoch 20/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 1.8763 - mae: 1.0324 - val_loss: 3.5546 - val_mae: 1.3110\n",
      "Epoch 21/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 1.6042 - mae: 0.9525 - val_loss: 3.2124 - val_mae: 1.2179\n",
      "Epoch 22/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 1.4997 - mae: 0.9268 - val_loss: 2.9279 - val_mae: 1.1651\n",
      "Epoch 23/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 1.3155 - mae: 0.8584 - val_loss: 2.7937 - val_mae: 1.1231\n",
      "Epoch 24/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 1.1675 - mae: 0.8151 - val_loss: 2.8070 - val_mae: 1.1009\n",
      "Epoch 25/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 1.0917 - mae: 0.7866 - val_loss: 3.1888 - val_mae: 1.1803\n",
      "Epoch 26/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.9932 - mae: 0.7512 - val_loss: 3.6079 - val_mae: 1.2189\n",
      "Epoch 27/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.9298 - mae: 0.7310 - val_loss: 2.7691 - val_mae: 1.0547\n",
      "Epoch 28/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.8825 - mae: 0.7063 - val_loss: 2.7089 - val_mae: 1.0325\n",
      "Epoch 29/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.8186 - mae: 0.6846 - val_loss: 3.0364 - val_mae: 1.0874\n",
      "Epoch 30/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.7971 - mae: 0.6682 - val_loss: 2.7533 - val_mae: 1.0409\n",
      "Epoch 31/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.7356 - mae: 0.6451 - val_loss: 2.7189 - val_mae: 1.0589\n",
      "Epoch 32/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.6808 - mae: 0.6208 - val_loss: 2.6261 - val_mae: 1.0046\n",
      "Epoch 33/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.6570 - mae: 0.6132 - val_loss: 2.4560 - val_mae: 0.9834\n",
      "Epoch 34/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.6307 - mae: 0.5952 - val_loss: 2.6134 - val_mae: 1.0016\n",
      "Epoch 35/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.6006 - mae: 0.5866 - val_loss: 2.7779 - val_mae: 1.0206\n",
      "Epoch 36/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.5640 - mae: 0.5691 - val_loss: 2.5932 - val_mae: 0.9896\n",
      "Epoch 37/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.5635 - mae: 0.5708 - val_loss: 2.4918 - val_mae: 0.9885\n",
      "Epoch 38/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.5409 - mae: 0.5534 - val_loss: 2.3479 - val_mae: 0.9231\n",
      "Epoch 39/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5287 - mae: 0.5457 - val_loss: 2.3111 - val_mae: 0.9052\n",
      "Epoch 40/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.5010 - mae: 0.5349 - val_loss: 2.3884 - val_mae: 0.9374\n",
      "Epoch 41/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.5069 - mae: 0.5378 - val_loss: 2.6319 - val_mae: 0.9782\n",
      "Epoch 42/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4893 - mae: 0.5244 - val_loss: 2.5133 - val_mae: 0.9316\n",
      "Epoch 43/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4605 - mae: 0.5149 - val_loss: 2.3841 - val_mae: 0.9143\n",
      "Epoch 44/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4589 - mae: 0.5127 - val_loss: 2.4416 - val_mae: 0.9421\n",
      "Epoch 45/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4420 - mae: 0.5028 - val_loss: 2.3809 - val_mae: 0.9140\n",
      "Epoch 46/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4352 - mae: 0.4950 - val_loss: 2.7307 - val_mae: 0.9576\n",
      "Epoch 47/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4294 - mae: 0.4976 - val_loss: 2.6279 - val_mae: 0.9252\n",
      "Epoch 48/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4168 - mae: 0.4857 - val_loss: 2.3163 - val_mae: 0.9048\n",
      "Epoch 49/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4151 - mae: 0.4842 - val_loss: 2.5817 - val_mae: 0.9274\n",
      "Epoch 50/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.4030 - mae: 0.4818 - val_loss: 2.1718 - val_mae: 0.8553\n",
      "Epoch 51/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.3999 - mae: 0.4770 - val_loss: 2.3241 - val_mae: 0.9185\n",
      "Epoch 52/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.3835 - mae: 0.4681 - val_loss: 2.4060 - val_mae: 0.8708\n",
      "Epoch 53/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.3776 - mae: 0.4628 - val_loss: 2.3269 - val_mae: 0.8699\n",
      "Epoch 54/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.3702 - mae: 0.4618 - val_loss: 2.4038 - val_mae: 0.8830\n",
      "Epoch 55/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.3549 - mae: 0.4499 - val_loss: 2.2510 - val_mae: 0.8610\n",
      "Epoch 56/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.3542 - mae: 0.4492 - val_loss: 2.4947 - val_mae: 0.9480\n",
      "Epoch 57/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.3615 - mae: 0.4543 - val_loss: 2.2127 - val_mae: 0.8427\n",
      "Epoch 58/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.3570 - mae: 0.4504 - val_loss: 2.3707 - val_mae: 0.8689\n",
      "Epoch 59/60\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 0.3456 - mae: 0.4425 - val_loss: 2.3565 - val_mae: 0.8674\n",
      "Epoch 60/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.3328 - mae: 0.4365 - val_loss: 2.1895 - val_mae: 0.8292\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d (Conv2D)             (None, 148, 148, 16)      160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9248)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1183872   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,214,561\n",
      "Trainable params: 1,214,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "113/113 [==============================] - 1s 5ms/step - loss: 2.1895 - mae: 0.8292\n",
      "[2.189467191696167, 0.8292473554611206]\n"
     ]
    }
   ],
   "source": [
    "#Regression with MeanSquaredError()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "\n",
    "#model.compile(loss=clock_loss,\n",
    "model.compile(loss=tf.keras.losses.MeanSquaredError(),#ClockLossAccuracy(),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=['mae'])\n",
    "\n",
    "model.fit(images[:split_idx], reg_labels[:split_idx],\n",
    "    batch_size=100,\n",
    "    epochs=60,\n",
    "    verbose=1,\n",
    "    validation_data=(images[split_idx:], reg_labels[split_idx:]))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "score = model.evaluate(images[split_idx:], reg_labels[split_idx:])\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "D3hOSDTSUqpm",
    "outputId": "a86300e2-21a5-48bc-a8d3-6daa2160b0f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 15:58:50.849128: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n",
      "2022-11-25 15:58:51.399327: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training Set 0.22403436338639368\n",
      "in minutes 13.442061803183622\n",
      "Accuracy for testing Set 0.7943823396491784\n",
      "in minutes 47.6629403789507\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(images[:split_idx]) % 12\n",
    "print(f'Accuracy for training Set {clock_loss_np(reg_labels[:split_idx],predictions.reshape((len(predictions))))}')\n",
    "print(f'in minutes {clock_loss_np(reg_labels[:split_idx],predictions.reshape((len(predictions))))*60}')\n",
    "\n",
    "predictions=model.predict(images[split_idx:]) % 12\n",
    "print(f'Accuracy for testing Set {clock_loss_np(reg_labels[split_idx:],predictions.reshape((len(predictions))))}')\n",
    "print(f'in minutes {clock_loss_np(reg_labels[split_idx:],predictions.reshape((len(predictions))))*60}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ClockLossAccuracy as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5z_EqKyVV3x",
    "outputId": "2257de4b-860d-41cb-ece6-7ddaae927856"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 15:58:54.115577: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "144/144 [==============================] - 4s 24ms/step - loss: 12.0466 - mae: 23.4246 - val_loss: 11.9172 - val_mae: 54.6066\n",
      "Epoch 2/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 11.8006 - mae: 30.3603 - val_loss: 11.8065 - val_mae: 9.0948\n",
      "Epoch 3/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 12.0406 - mae: 6.1715 - val_loss: 12.0942 - val_mae: 4.2342\n",
      "Epoch 4/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 12.0307 - mae: 5.0244 - val_loss: 12.0972 - val_mae: 3.9747\n",
      "Epoch 5/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 11.8913 - mae: 5.2470 - val_loss: 11.8866 - val_mae: 6.5217\n",
      "Epoch 6/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 10.9466 - mae: 6.7749 - val_loss: 8.3911 - val_mae: 7.2989\n",
      "Epoch 7/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 8.3524 - mae: 7.1526 - val_loss: 6.9379 - val_mae: 7.3762\n",
      "Epoch 8/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 7.0637 - mae: 7.5085 - val_loss: 6.9844 - val_mae: 9.0121\n",
      "Epoch 9/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 6.1919 - mae: 7.5589 - val_loss: 5.4329 - val_mae: 7.0290\n",
      "Epoch 10/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 5.4248 - mae: 7.5209 - val_loss: 4.6923 - val_mae: 7.0653\n",
      "Epoch 11/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 4.7826 - mae: 7.5905 - val_loss: 3.9876 - val_mae: 7.6196\n",
      "Epoch 12/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 4.3442 - mae: 7.5347 - val_loss: 3.4378 - val_mae: 7.9477\n",
      "Epoch 13/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 3.8285 - mae: 7.6817 - val_loss: 2.9858 - val_mae: 7.8402\n",
      "Epoch 14/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 3.3594 - mae: 7.6518 - val_loss: 2.8018 - val_mae: 8.0566\n",
      "Epoch 15/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 2.9980 - mae: 7.5313 - val_loss: 2.8934 - val_mae: 7.2080\n",
      "Epoch 16/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 2.6743 - mae: 7.6123 - val_loss: 2.5884 - val_mae: 7.3183\n",
      "Epoch 17/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 2.4134 - mae: 7.5665 - val_loss: 2.3624 - val_mae: 7.9838\n",
      "Epoch 18/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 2.1882 - mae: 7.6116 - val_loss: 3.1287 - val_mae: 7.0283\n",
      "Epoch 19/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 2.0108 - mae: 7.5801 - val_loss: 2.1133 - val_mae: 7.5987\n",
      "Epoch 20/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 1.8441 - mae: 7.6021 - val_loss: 1.7716 - val_mae: 7.6822\n",
      "Epoch 21/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 1.6683 - mae: 7.6368 - val_loss: 1.5731 - val_mae: 7.9134\n",
      "Epoch 22/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 1.5679 - mae: 7.6490 - val_loss: 1.4943 - val_mae: 7.8683\n",
      "Epoch 23/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 1.4494 - mae: 7.6103 - val_loss: 1.8146 - val_mae: 8.1161\n",
      "Epoch 24/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 1.3911 - mae: 7.5833 - val_loss: 1.7371 - val_mae: 7.5213\n",
      "Epoch 25/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 1.2854 - mae: 7.5904 - val_loss: 1.3185 - val_mae: 7.9346\n",
      "Epoch 26/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 1.1992 - mae: 7.6082 - val_loss: 1.3820 - val_mae: 7.5850\n",
      "Epoch 27/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 1.1372 - mae: 7.6229 - val_loss: 1.4411 - val_mae: 7.8856\n",
      "Epoch 28/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 1.1330 - mae: 7.6056 - val_loss: 1.4673 - val_mae: 7.9657\n",
      "Epoch 29/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 1.1182 - mae: 7.5894 - val_loss: 1.5546 - val_mae: 7.4451\n",
      "Epoch 30/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 1.0639 - mae: 7.6035 - val_loss: 1.5826 - val_mae: 7.5810\n",
      "Epoch 31/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.9713 - mae: 7.5930 - val_loss: 1.3907 - val_mae: 7.5971\n",
      "Epoch 32/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.9073 - mae: 7.6014 - val_loss: 1.1652 - val_mae: 7.6791\n",
      "Epoch 33/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.8343 - mae: 7.5950 - val_loss: 1.1621 - val_mae: 7.7812\n",
      "Epoch 34/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.8771 - mae: 7.5341 - val_loss: 1.5410 - val_mae: 7.4864\n",
      "Epoch 35/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.8492 - mae: 7.5644 - val_loss: 1.3076 - val_mae: 7.6338\n",
      "Epoch 36/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.7969 - mae: 7.5536 - val_loss: 1.1383 - val_mae: 7.8267\n",
      "Epoch 37/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.7554 - mae: 7.5756 - val_loss: 1.1905 - val_mae: 7.5992\n",
      "Epoch 38/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.7714 - mae: 7.5603 - val_loss: 1.1502 - val_mae: 7.6186\n",
      "Epoch 39/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.7365 - mae: 7.5513 - val_loss: 1.1100 - val_mae: 7.6573\n",
      "Epoch 40/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.7363 - mae: 7.5425 - val_loss: 1.0371 - val_mae: 7.8131\n",
      "Epoch 41/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.7389 - mae: 7.6037 - val_loss: 1.0224 - val_mae: 7.6430\n",
      "Epoch 42/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.6715 - mae: 7.5655 - val_loss: 0.9378 - val_mae: 7.8180\n",
      "Epoch 43/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.6450 - mae: 7.5862 - val_loss: 1.0177 - val_mae: 7.7982\n",
      "Epoch 44/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.6953 - mae: 7.5997 - val_loss: 1.4351 - val_mae: 7.9796\n",
      "Epoch 45/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5833 - mae: 7.5649 - val_loss: 0.9764 - val_mae: 7.7217\n",
      "Epoch 46/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5795 - mae: 7.5555 - val_loss: 0.9862 - val_mae: 7.7140\n",
      "Epoch 47/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.6037 - mae: 7.5794 - val_loss: 1.2143 - val_mae: 7.9228\n",
      "Epoch 48/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5449 - mae: 7.5658 - val_loss: 1.0232 - val_mae: 7.6664\n",
      "Epoch 49/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5126 - mae: 7.5529 - val_loss: 0.8968 - val_mae: 7.6155\n",
      "Epoch 50/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5333 - mae: 7.5583 - val_loss: 0.9564 - val_mae: 7.7841\n",
      "Epoch 51/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.5259 - mae: 7.5481 - val_loss: 0.9717 - val_mae: 7.7583\n",
      "Epoch 52/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.4970 - mae: 7.5578 - val_loss: 0.9133 - val_mae: 7.7951\n",
      "Epoch 53/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.4604 - mae: 7.5536 - val_loss: 1.0088 - val_mae: 7.8801\n",
      "Epoch 54/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4714 - mae: 7.5557 - val_loss: 1.0221 - val_mae: 7.8182\n",
      "Epoch 55/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4757 - mae: 7.5571 - val_loss: 0.9562 - val_mae: 7.8957\n",
      "Epoch 56/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4634 - mae: 7.5581 - val_loss: 0.9548 - val_mae: 7.7814\n",
      "Epoch 57/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4770 - mae: 7.5473 - val_loss: 0.8978 - val_mae: 7.9325\n",
      "Epoch 58/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4778 - mae: 7.5440 - val_loss: 0.9787 - val_mae: 7.7467\n",
      "Epoch 59/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4726 - mae: 7.5499 - val_loss: 1.0014 - val_mae: 7.7509\n",
      "Epoch 60/60\n",
      "144/144 [==============================] - 3s 21ms/step - loss: 0.4638 - mae: 7.5533 - val_loss: 0.8562 - val_mae: 7.7918\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 148, 148, 16)      160       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 74, 74, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 72, 72, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 34, 34, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 17, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 9248)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               1183872   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,214,561\n",
      "Trainable params: 1,214,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "113/113 [==============================] - 1s 5ms/step - loss: 0.8562 - mae: 7.7918\n",
      "[0.8561860918998718, 7.791819095611572]\n"
     ]
    }
   ],
   "source": [
    "#Regression with ClockLossAccuracy()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "\n",
    "#model.compile(loss=clock_loss,\n",
    "model.compile(loss=ClockLossAccuracy(),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=['mae'])\n",
    "\n",
    "model.fit(images[:split_idx], reg_labels[:split_idx],\n",
    "    batch_size=100,\n",
    "    epochs=60,\n",
    "    verbose=1,\n",
    "    validation_data=(images[split_idx:], reg_labels[split_idx:]))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "score = model.evaluate(images[split_idx:], reg_labels[split_idx:])\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "E-NulG6AVc01",
    "outputId": "63b9da26-8883-4e40-e2b7-3d60bed6936b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training Set 0.2821223483772741\n",
      "in minutes 16.92734090263645\n",
      "Accuracy for testing Set 0.5550967877529286\n",
      "in minutes 33.305807265175716\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(images[:split_idx]) % 12\n",
    "print(f'Accuracy for training Set {clock_loss_np(reg_labels[:split_idx],predictions.reshape((len(predictions))))}')\n",
    "print(f'in minutes {clock_loss_np(reg_labels[:split_idx],predictions.reshape((len(predictions))))*60}')\n",
    "\n",
    "predictions=model.predict(images[split_idx:]) % 12\n",
    "print(f'Accuracy for testing Set {clock_loss_np(reg_labels[split_idx:],predictions.reshape((len(predictions))))}')\n",
    "print(f'in minutes {clock_loss_np(reg_labels[split_idx:],predictions.reshape((len(predictions))))*60}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DwoDGQiHgkNq"
   },
   "outputs": [],
   "source": [
    "def classification_time(num_classes):\n",
    "    # Classification, half an hour\n",
    "    class_labels = ((num_classes/12)*reg_labels).astype('int')\n",
    "    #print(reg_labels[100])\n",
    "    #print(class_labels[100])\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "\n",
    "    y_train = keras.utils.to_categorical(class_labels[:split_idx], num_classes)\n",
    "    y_test = keras.utils.to_categorical(class_labels[split_idx:], num_classes)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))#, kernel_regularizer=tf.keras.regularizers.L2(l2=0.01)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(128, activation='relu'))#, kernel_regularizer=tf.keras.regularizers.L2(l2=0.01)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                #optimizer=keras.optimizers.Adadelta(),\n",
    "                optimizer=keras.optimizers.RMSprop(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_images, y_train,\n",
    "            batch_size=100,\n",
    "            epochs=60,\n",
    "            verbose=1,\n",
    "            validation_data=(test_images, y_test))\n",
    "    print(model.summary())\n",
    "    score = model.evaluate(test_images, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    print('-------------------')\n",
    "\n",
    "\n",
    "    #printing the common sense accuracy\n",
    "    \n",
    "    predictions_train=model.predict(train_images)\n",
    "    pred_train=np.empty(len(predictions_train))\n",
    "    for i in range(len(predictions_train)):\n",
    "        pred_train[i]=np.argmax(predictions_train[i])\n",
    "        \n",
    "    predictions_test=model.predict(test_images)\n",
    "    pred_test=np.empty(len(predictions_test))\n",
    "    for i in range(len(predictions_test)):\n",
    "        pred_test[i]=np.argmax(predictions_test[i])\n",
    "\n",
    "    loss_train=clock_loss_np(reg_labels[:split_idx],pred_train/(num_classes/12))\n",
    "    loss_test=clock_loss_np(reg_labels[split_idx:],pred_test/(num_classes/12))\n",
    "    print(f'Common sense accurasy')\n",
    "    print(f'train MAE = {loss_train}')\n",
    "    print(f'in minutes = {loss_train*60}')\n",
    "    print(f'test MAE = {loss_test}')\n",
    "    print(f'in minutes = {loss_test*60}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Ar7iHZIjKrz",
    "outputId": "878d127d-6822-4075-b248-fc2cee0c420e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:04:04.104693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:04:04.105093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:04:04.105216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:04:04.106106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:04:04.106280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:04:04.106506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:04:04.106859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:04:04.107042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:04:04.107174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6147 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2022-11-25 16:04:04.276891: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n",
      "2022-11-25 16:04:04.783489: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:04:06.404551: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "2022-11-25 16:04:07.050752: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 16:04:07.051221: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 16:04:07.051233: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-11-25 16:04:07.051546: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 16:04:07.051583: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-11-25 16:04:07.684317: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 7s 30ms/step - loss: 3.1833 - accuracy: 0.0401 - val_loss: 3.1831 - val_accuracy: 0.0400\n",
      "Epoch 2/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 3.1795 - accuracy: 0.0438 - val_loss: 3.1785 - val_accuracy: 0.0358\n",
      "Epoch 3/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 3.1701 - accuracy: 0.0492 - val_loss: 3.0951 - val_accuracy: 0.0653\n",
      "Epoch 4/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.8639 - accuracy: 0.1071 - val_loss: 2.5957 - val_accuracy: 0.1661\n",
      "Epoch 5/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.5081 - accuracy: 0.1707 - val_loss: 2.3213 - val_accuracy: 0.2328\n",
      "Epoch 6/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.3203 - accuracy: 0.2268 - val_loss: 2.1293 - val_accuracy: 0.2833\n",
      "Epoch 7/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.1367 - accuracy: 0.2776 - val_loss: 1.9655 - val_accuracy: 0.3322\n",
      "Epoch 8/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.9591 - accuracy: 0.3317 - val_loss: 1.7570 - val_accuracy: 0.3964\n",
      "Epoch 9/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.7914 - accuracy: 0.3787 - val_loss: 1.5845 - val_accuracy: 0.4378\n",
      "Epoch 10/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.6169 - accuracy: 0.4328 - val_loss: 1.4646 - val_accuracy: 0.4886\n",
      "Epoch 11/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.4786 - accuracy: 0.4748 - val_loss: 1.3855 - val_accuracy: 0.5311\n",
      "Epoch 12/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.3797 - accuracy: 0.5067 - val_loss: 1.2433 - val_accuracy: 0.5692\n",
      "Epoch 13/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.2693 - accuracy: 0.5410 - val_loss: 1.2028 - val_accuracy: 0.5833\n",
      "Epoch 14/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.1691 - accuracy: 0.5776 - val_loss: 1.0931 - val_accuracy: 0.6189\n",
      "Epoch 15/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.0800 - accuracy: 0.6080 - val_loss: 0.9967 - val_accuracy: 0.6506\n",
      "Epoch 16/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.9883 - accuracy: 0.6350 - val_loss: 0.9871 - val_accuracy: 0.6533\n",
      "Epoch 17/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.9137 - accuracy: 0.6643 - val_loss: 0.9453 - val_accuracy: 0.6722\n",
      "Epoch 18/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.8505 - accuracy: 0.6866 - val_loss: 0.9349 - val_accuracy: 0.6636\n",
      "Epoch 19/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.7986 - accuracy: 0.7080 - val_loss: 0.8585 - val_accuracy: 0.7017\n",
      "Epoch 20/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.7386 - accuracy: 0.7283 - val_loss: 0.8164 - val_accuracy: 0.7125\n",
      "Epoch 21/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.6855 - accuracy: 0.7467 - val_loss: 0.7829 - val_accuracy: 0.7367\n",
      "Epoch 22/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.6355 - accuracy: 0.7697 - val_loss: 0.7825 - val_accuracy: 0.7278\n",
      "Epoch 23/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.5892 - accuracy: 0.7869 - val_loss: 0.9565 - val_accuracy: 0.6739\n",
      "Epoch 24/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.5617 - accuracy: 0.7947 - val_loss: 0.7597 - val_accuracy: 0.7364\n",
      "Epoch 25/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.5181 - accuracy: 0.8110 - val_loss: 0.7398 - val_accuracy: 0.7514\n",
      "Epoch 26/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.4922 - accuracy: 0.8244 - val_loss: 0.6819 - val_accuracy: 0.7811\n",
      "Epoch 27/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.4640 - accuracy: 0.8319 - val_loss: 0.7347 - val_accuracy: 0.7608\n",
      "Epoch 28/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.4423 - accuracy: 0.8429 - val_loss: 0.6999 - val_accuracy: 0.7672\n",
      "Epoch 29/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.4102 - accuracy: 0.8519 - val_loss: 0.7003 - val_accuracy: 0.7772\n",
      "Epoch 30/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.3930 - accuracy: 0.8616 - val_loss: 0.6793 - val_accuracy: 0.7911\n",
      "Epoch 31/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.3700 - accuracy: 0.8680 - val_loss: 0.6445 - val_accuracy: 0.7981\n",
      "Epoch 32/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.3605 - accuracy: 0.8737 - val_loss: 0.7103 - val_accuracy: 0.7878\n",
      "Epoch 33/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.3426 - accuracy: 0.8789 - val_loss: 0.7203 - val_accuracy: 0.7844\n",
      "Epoch 34/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.3311 - accuracy: 0.8830 - val_loss: 0.6455 - val_accuracy: 0.8003\n",
      "Epoch 35/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.3168 - accuracy: 0.8901 - val_loss: 0.6693 - val_accuracy: 0.7972\n",
      "Epoch 36/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.3003 - accuracy: 0.8930 - val_loss: 0.6512 - val_accuracy: 0.8019\n",
      "Epoch 37/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.3013 - accuracy: 0.8970 - val_loss: 1.0687 - val_accuracy: 0.7244\n",
      "Epoch 38/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.2708 - accuracy: 0.9058 - val_loss: 0.6927 - val_accuracy: 0.7994\n",
      "Epoch 39/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.2712 - accuracy: 0.9082 - val_loss: 0.6314 - val_accuracy: 0.8069\n",
      "Epoch 40/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.2638 - accuracy: 0.9082 - val_loss: 0.6617 - val_accuracy: 0.8072\n",
      "Epoch 41/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.2477 - accuracy: 0.9140 - val_loss: 0.6837 - val_accuracy: 0.8044\n",
      "Epoch 42/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.2417 - accuracy: 0.9176 - val_loss: 0.6567 - val_accuracy: 0.8117\n",
      "Epoch 43/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.2317 - accuracy: 0.9190 - val_loss: 0.7168 - val_accuracy: 0.8122\n",
      "Epoch 44/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.2272 - accuracy: 0.9212 - val_loss: 0.6920 - val_accuracy: 0.8136\n",
      "Epoch 45/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.2211 - accuracy: 0.9239 - val_loss: 0.6981 - val_accuracy: 0.8028\n",
      "Epoch 46/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.2152 - accuracy: 0.9224 - val_loss: 0.6877 - val_accuracy: 0.8247\n",
      "Epoch 47/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.2099 - accuracy: 0.9256 - val_loss: 0.6801 - val_accuracy: 0.8111\n",
      "Epoch 48/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.2051 - accuracy: 0.9294 - val_loss: 0.7022 - val_accuracy: 0.8175\n",
      "Epoch 49/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.2017 - accuracy: 0.9308 - val_loss: 0.6548 - val_accuracy: 0.8256\n",
      "Epoch 50/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.1937 - accuracy: 0.9340 - val_loss: 0.7089 - val_accuracy: 0.8189\n",
      "Epoch 51/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.1886 - accuracy: 0.9344 - val_loss: 0.7526 - val_accuracy: 0.8094\n",
      "Epoch 52/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.1789 - accuracy: 0.9407 - val_loss: 0.8468 - val_accuracy: 0.7953\n",
      "Epoch 53/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.1859 - accuracy: 0.9368 - val_loss: 0.6784 - val_accuracy: 0.8286\n",
      "Epoch 54/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.1722 - accuracy: 0.9396 - val_loss: 0.6922 - val_accuracy: 0.8247\n",
      "Epoch 55/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.1676 - accuracy: 0.9417 - val_loss: 0.6627 - val_accuracy: 0.8269\n",
      "Epoch 56/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.1780 - accuracy: 0.9394 - val_loss: 0.6995 - val_accuracy: 0.8289\n",
      "Epoch 57/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.1607 - accuracy: 0.9469 - val_loss: 0.7094 - val_accuracy: 0.8194\n",
      "Epoch 58/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 4s 28ms/step - loss: 0.1512 - accuracy: 0.9486 - val_loss: 0.7505 - val_accuracy: 0.8169\n",
      "Epoch 59/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.1556 - accuracy: 0.9483 - val_loss: 0.6885 - val_accuracy: 0.8344\n",
      "Epoch 60/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.1511 - accuracy: 0.9483 - val_loss: 0.7001 - val_accuracy: 0.8208\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9248)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1183872   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,222,296\n",
      "Trainable params: 1,222,296\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test loss: 0.7001155018806458\n",
      "Test accuracy: 0.8208333253860474\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:08:14.571752: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n",
      "2022-11-25 16:08:15.138970: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common sense accurasy\n",
      "train MAE = 0.24372685185185186\n",
      "in minutes = 14.623611111111112\n",
      "test MAE = 0.4132037037037037\n",
      "in minutes = 24.79222222222222\n"
     ]
    }
   ],
   "source": [
    "classification_time(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 48 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jczfIOAJaMjT",
    "outputId": "f79d780e-effe-4ca6-e34c-3a1098d630ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:14:26.139711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:14:26.140071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:14:26.140238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:14:26.141075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:14:26.141361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:14:26.141513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:14:26.141709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:14:26.141933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:14:26.142045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6147 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2022-11-25 16:14:26.283633: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n",
      "2022-11-25 16:14:26.810469: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:14:28.538461: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "2022-11-25 16:14:29.217362: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 16:14:29.218033: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 16:14:29.218049: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-11-25 16:14:29.218379: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 16:14:29.218419: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-11-25 16:14:29.874607: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 8s 32ms/step - loss: 3.8732 - accuracy: 0.0194 - val_loss: 3.8718 - val_accuracy: 0.0192\n",
      "Epoch 2/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 3.8721 - accuracy: 0.0199 - val_loss: 3.8725 - val_accuracy: 0.0178\n",
      "Epoch 3/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 3.8636 - accuracy: 0.0235 - val_loss: 3.8222 - val_accuracy: 0.0275\n",
      "Epoch 4/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 3.5286 - accuracy: 0.0676 - val_loss: 3.0587 - val_accuracy: 0.1361\n",
      "Epoch 5/60\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 2.9847 - accuracy: 0.1422 - val_loss: 2.7130 - val_accuracy: 0.1950\n",
      "Epoch 6/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.6908 - accuracy: 0.1896 - val_loss: 2.5257 - val_accuracy: 0.2206\n",
      "Epoch 7/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.4480 - accuracy: 0.2419 - val_loss: 2.1786 - val_accuracy: 0.3000\n",
      "Epoch 8/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.2255 - accuracy: 0.2880 - val_loss: 1.9348 - val_accuracy: 0.3475\n",
      "Epoch 9/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.0391 - accuracy: 0.3328 - val_loss: 1.7777 - val_accuracy: 0.3986\n",
      "Epoch 10/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.8565 - accuracy: 0.3841 - val_loss: 1.6169 - val_accuracy: 0.4758\n",
      "Epoch 11/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.6962 - accuracy: 0.4201 - val_loss: 1.4943 - val_accuracy: 0.4922\n",
      "Epoch 12/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.5502 - accuracy: 0.4655 - val_loss: 1.3841 - val_accuracy: 0.5294\n",
      "Epoch 13/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.4329 - accuracy: 0.5002 - val_loss: 1.2256 - val_accuracy: 0.5892\n",
      "Epoch 14/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.3211 - accuracy: 0.5377 - val_loss: 1.2959 - val_accuracy: 0.5550\n",
      "Epoch 15/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.2101 - accuracy: 0.5778 - val_loss: 1.1238 - val_accuracy: 0.6253\n",
      "Epoch 16/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.1409 - accuracy: 0.6019 - val_loss: 1.0397 - val_accuracy: 0.6497\n",
      "Epoch 17/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.0219 - accuracy: 0.6410 - val_loss: 0.9830 - val_accuracy: 0.6614\n",
      "Epoch 18/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.9881 - accuracy: 0.6540 - val_loss: 0.9650 - val_accuracy: 0.6739\n",
      "Epoch 19/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.9053 - accuracy: 0.6828 - val_loss: 1.0015 - val_accuracy: 0.6617\n",
      "Epoch 20/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.8386 - accuracy: 0.7105 - val_loss: 0.9311 - val_accuracy: 0.6733\n",
      "Epoch 21/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.7835 - accuracy: 0.7213 - val_loss: 0.8863 - val_accuracy: 0.6986\n",
      "Epoch 22/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.7317 - accuracy: 0.7410 - val_loss: 0.8332 - val_accuracy: 0.7181\n",
      "Epoch 23/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.6895 - accuracy: 0.7574 - val_loss: 0.8511 - val_accuracy: 0.7128\n",
      "Epoch 24/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.6476 - accuracy: 0.7733 - val_loss: 0.9506 - val_accuracy: 0.6781\n",
      "Epoch 25/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.6096 - accuracy: 0.7842 - val_loss: 0.8115 - val_accuracy: 0.7311\n",
      "Epoch 26/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.5844 - accuracy: 0.7948 - val_loss: 0.8996 - val_accuracy: 0.7036\n",
      "Epoch 27/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.5382 - accuracy: 0.8136 - val_loss: 0.8175 - val_accuracy: 0.7317\n",
      "Epoch 28/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.5044 - accuracy: 0.8251 - val_loss: 0.8446 - val_accuracy: 0.7303\n",
      "Epoch 29/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.4751 - accuracy: 0.8387 - val_loss: 0.8526 - val_accuracy: 0.7336\n",
      "Epoch 30/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.4652 - accuracy: 0.8404 - val_loss: 0.8511 - val_accuracy: 0.7397\n",
      "Epoch 31/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.4376 - accuracy: 0.8501 - val_loss: 0.7854 - val_accuracy: 0.7536\n",
      "Epoch 32/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.4156 - accuracy: 0.8565 - val_loss: 0.8325 - val_accuracy: 0.7514\n",
      "Epoch 33/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.4048 - accuracy: 0.8606 - val_loss: 0.8072 - val_accuracy: 0.7606\n",
      "Epoch 34/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.3845 - accuracy: 0.8687 - val_loss: 0.8181 - val_accuracy: 0.7542\n",
      "Epoch 35/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.3688 - accuracy: 0.8786 - val_loss: 0.7696 - val_accuracy: 0.7689\n",
      "Epoch 36/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.3617 - accuracy: 0.8783 - val_loss: 0.8573 - val_accuracy: 0.7411\n",
      "Epoch 37/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.3463 - accuracy: 0.8849 - val_loss: 0.7791 - val_accuracy: 0.7656\n",
      "Epoch 38/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.3299 - accuracy: 0.8849 - val_loss: 0.7948 - val_accuracy: 0.7689\n",
      "Epoch 39/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.3059 - accuracy: 0.8965 - val_loss: 0.8055 - val_accuracy: 0.7606\n",
      "Epoch 40/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.3066 - accuracy: 0.8944 - val_loss: 0.8138 - val_accuracy: 0.7642\n",
      "Epoch 41/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.2931 - accuracy: 0.9011 - val_loss: 0.9074 - val_accuracy: 0.7511\n",
      "Epoch 42/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.2770 - accuracy: 0.9069 - val_loss: 0.9031 - val_accuracy: 0.7506\n",
      "Epoch 43/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.2663 - accuracy: 0.9098 - val_loss: 0.8881 - val_accuracy: 0.7553\n",
      "Epoch 44/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.2646 - accuracy: 0.9094 - val_loss: 0.8284 - val_accuracy: 0.7539\n",
      "Epoch 45/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.2517 - accuracy: 0.9106 - val_loss: 0.8532 - val_accuracy: 0.7500\n",
      "Epoch 46/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.2441 - accuracy: 0.9178 - val_loss: 0.8322 - val_accuracy: 0.7636\n",
      "Epoch 47/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.2444 - accuracy: 0.9194 - val_loss: 0.9229 - val_accuracy: 0.7492\n",
      "Epoch 48/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.2272 - accuracy: 0.9212 - val_loss: 0.8495 - val_accuracy: 0.7786\n",
      "Epoch 49/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.2242 - accuracy: 0.9229 - val_loss: 0.9035 - val_accuracy: 0.7689\n",
      "Epoch 50/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.2264 - accuracy: 0.9241 - val_loss: 0.8809 - val_accuracy: 0.7703\n",
      "Epoch 51/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.2164 - accuracy: 0.9282 - val_loss: 0.9076 - val_accuracy: 0.7689\n",
      "Epoch 52/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.2095 - accuracy: 0.9288 - val_loss: 0.9222 - val_accuracy: 0.7656\n",
      "Epoch 53/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.2012 - accuracy: 0.9318 - val_loss: 0.9487 - val_accuracy: 0.7625\n",
      "Epoch 54/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.2141 - accuracy: 0.9297 - val_loss: 0.8960 - val_accuracy: 0.7628\n",
      "Epoch 55/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.1937 - accuracy: 0.9353 - val_loss: 0.8575 - val_accuracy: 0.7736\n",
      "Epoch 56/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.1854 - accuracy: 0.9374 - val_loss: 0.8999 - val_accuracy: 0.7797\n",
      "Epoch 57/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.1817 - accuracy: 0.9375 - val_loss: 0.9185 - val_accuracy: 0.7658\n",
      "Epoch 58/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 4s 29ms/step - loss: 0.1879 - accuracy: 0.9381 - val_loss: 0.9093 - val_accuracy: 0.7772\n",
      "Epoch 59/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.1812 - accuracy: 0.9417 - val_loss: 0.9463 - val_accuracy: 0.7669\n",
      "Epoch 60/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.1796 - accuracy: 0.9403 - val_loss: 0.9556 - val_accuracy: 0.7811\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9248)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1183872   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 48)                6192      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,225,392\n",
      "Trainable params: 1,225,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test loss: 0.9555545449256897\n",
      "Test accuracy: 0.7811111211776733\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:18:38.305445: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n",
      "2022-11-25 16:18:38.756162: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common sense accurasy\n",
      "train MAE = 0.11817129629629629\n",
      "in minutes = 7.090277777777778\n",
      "test MAE = 0.3815\n",
      "in minutes = 22.89\n"
     ]
    }
   ],
   "source": [
    "classification_time(48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 120 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:19:46.549002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:19:46.549501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:19:46.549643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:19:46.550081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:19:46.550259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:19:46.550413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:19:46.550611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:19:46.550771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:19:46.550887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6147 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2022-11-25 16:19:46.693399: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n",
      "2022-11-25 16:19:47.195070: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:19:48.647850: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "2022-11-25 16:19:49.324758: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 16:19:49.327206: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 16:19:49.327253: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-11-25 16:19:49.327834: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 16:19:49.327894: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-11-25 16:19:49.989548: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 7s 31ms/step - loss: 4.7897 - accuracy: 0.0069 - val_loss: 4.7885 - val_accuracy: 0.0072\n",
      "Epoch 2/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 4.7884 - accuracy: 0.0076 - val_loss: 4.7893 - val_accuracy: 0.0056\n",
      "Epoch 3/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 4.7881 - accuracy: 0.0084 - val_loss: 4.7897 - val_accuracy: 0.0061\n",
      "Epoch 4/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 4.7880 - accuracy: 0.0084 - val_loss: 4.7902 - val_accuracy: 0.0056\n",
      "Epoch 5/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 4.7879 - accuracy: 0.0078 - val_loss: 4.7902 - val_accuracy: 0.0056\n",
      "Epoch 6/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 4.7879 - accuracy: 0.0070 - val_loss: 4.7911 - val_accuracy: 0.0058\n",
      "Epoch 7/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 4.7879 - accuracy: 0.0075 - val_loss: 4.7907 - val_accuracy: 0.0056\n",
      "Epoch 8/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 4.7861 - accuracy: 0.0082 - val_loss: 4.7876 - val_accuracy: 0.0111\n",
      "Epoch 9/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 4.6753 - accuracy: 0.0175 - val_loss: 4.4699 - val_accuracy: 0.0278\n",
      "Epoch 10/60\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 4.2153 - accuracy: 0.0416 - val_loss: 3.8289 - val_accuracy: 0.0756\n",
      "Epoch 11/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 3.7432 - accuracy: 0.0854 - val_loss: 3.4147 - val_accuracy: 0.1117\n",
      "Epoch 12/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 3.4122 - accuracy: 0.1223 - val_loss: 3.0331 - val_accuracy: 0.1728\n",
      "Epoch 13/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 3.1555 - accuracy: 0.1492 - val_loss: 2.7952 - val_accuracy: 0.2092\n",
      "Epoch 14/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.9172 - accuracy: 0.1852 - val_loss: 2.5542 - val_accuracy: 0.2619\n",
      "Epoch 15/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.7067 - accuracy: 0.2219 - val_loss: 2.3593 - val_accuracy: 0.2817\n",
      "Epoch 16/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.5212 - accuracy: 0.2498 - val_loss: 2.2646 - val_accuracy: 0.2978\n",
      "Epoch 17/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.3640 - accuracy: 0.2790 - val_loss: 2.0321 - val_accuracy: 0.3517\n",
      "Epoch 18/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.2447 - accuracy: 0.3058 - val_loss: 1.9953 - val_accuracy: 0.3617\n",
      "Epoch 19/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.1100 - accuracy: 0.3375 - val_loss: 1.8095 - val_accuracy: 0.4136\n",
      "Epoch 20/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.0061 - accuracy: 0.3579 - val_loss: 1.7182 - val_accuracy: 0.4275\n",
      "Epoch 21/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.9132 - accuracy: 0.3774 - val_loss: 1.8063 - val_accuracy: 0.4000\n",
      "Epoch 22/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.8428 - accuracy: 0.4003 - val_loss: 1.5982 - val_accuracy: 0.4642\n",
      "Epoch 23/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.7641 - accuracy: 0.4215 - val_loss: 1.6072 - val_accuracy: 0.4583\n",
      "Epoch 24/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.6705 - accuracy: 0.4439 - val_loss: 1.4707 - val_accuracy: 0.4931\n",
      "Epoch 25/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.6195 - accuracy: 0.4608 - val_loss: 1.4712 - val_accuracy: 0.4922\n",
      "Epoch 26/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.5485 - accuracy: 0.4815 - val_loss: 1.4414 - val_accuracy: 0.5064\n",
      "Epoch 27/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.4763 - accuracy: 0.5105 - val_loss: 1.4657 - val_accuracy: 0.4917\n",
      "Epoch 28/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.4376 - accuracy: 0.5200 - val_loss: 1.3854 - val_accuracy: 0.5281\n",
      "Epoch 29/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.3567 - accuracy: 0.5412 - val_loss: 1.3736 - val_accuracy: 0.5244\n",
      "Epoch 30/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.3198 - accuracy: 0.5568 - val_loss: 1.2995 - val_accuracy: 0.5486\n",
      "Epoch 31/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.2623 - accuracy: 0.5770 - val_loss: 1.3339 - val_accuracy: 0.5403\n",
      "Epoch 32/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.2344 - accuracy: 0.5844 - val_loss: 1.2733 - val_accuracy: 0.5700\n",
      "Epoch 33/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.1835 - accuracy: 0.6003 - val_loss: 1.3074 - val_accuracy: 0.5567\n",
      "Epoch 34/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.1373 - accuracy: 0.6128 - val_loss: 1.2962 - val_accuracy: 0.5500\n",
      "Epoch 35/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.1045 - accuracy: 0.6249 - val_loss: 1.1869 - val_accuracy: 0.5981\n",
      "Epoch 36/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.0509 - accuracy: 0.6441 - val_loss: 1.2448 - val_accuracy: 0.5836\n",
      "Epoch 37/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.0112 - accuracy: 0.6578 - val_loss: 1.3066 - val_accuracy: 0.5578\n",
      "Epoch 38/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.9717 - accuracy: 0.6796 - val_loss: 1.2400 - val_accuracy: 0.5861\n",
      "Epoch 39/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.9433 - accuracy: 0.6872 - val_loss: 1.2293 - val_accuracy: 0.5825\n",
      "Epoch 40/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.9107 - accuracy: 0.6972 - val_loss: 1.2018 - val_accuracy: 0.5939\n",
      "Epoch 41/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.8832 - accuracy: 0.7058 - val_loss: 1.2632 - val_accuracy: 0.5847\n",
      "Epoch 42/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.8535 - accuracy: 0.7190 - val_loss: 1.2602 - val_accuracy: 0.5817\n",
      "Epoch 43/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.8166 - accuracy: 0.7310 - val_loss: 1.2203 - val_accuracy: 0.5975\n",
      "Epoch 44/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.7786 - accuracy: 0.7414 - val_loss: 1.1844 - val_accuracy: 0.6042\n",
      "Epoch 45/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.7669 - accuracy: 0.7467 - val_loss: 1.2561 - val_accuracy: 0.5833\n",
      "Epoch 46/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.7360 - accuracy: 0.7614 - val_loss: 1.2274 - val_accuracy: 0.6014\n",
      "Epoch 47/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.7051 - accuracy: 0.7713 - val_loss: 1.1682 - val_accuracy: 0.6239\n",
      "Epoch 48/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.6819 - accuracy: 0.7800 - val_loss: 1.2050 - val_accuracy: 0.6253\n",
      "Epoch 49/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.6539 - accuracy: 0.7862 - val_loss: 1.2811 - val_accuracy: 0.6019\n",
      "Epoch 50/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.6545 - accuracy: 0.7894 - val_loss: 1.2609 - val_accuracy: 0.6092\n",
      "Epoch 51/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.6358 - accuracy: 0.7994 - val_loss: 1.2322 - val_accuracy: 0.6175\n",
      "Epoch 52/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.6153 - accuracy: 0.8048 - val_loss: 1.2029 - val_accuracy: 0.6203\n",
      "Epoch 53/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.5834 - accuracy: 0.8138 - val_loss: 1.2298 - val_accuracy: 0.6264\n",
      "Epoch 54/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.5621 - accuracy: 0.8167 - val_loss: 1.3349 - val_accuracy: 0.6197\n",
      "Epoch 55/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.5553 - accuracy: 0.8222 - val_loss: 1.2704 - val_accuracy: 0.6147\n",
      "Epoch 56/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.5193 - accuracy: 0.8330 - val_loss: 1.2940 - val_accuracy: 0.6183\n",
      "Epoch 57/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.5141 - accuracy: 0.8335 - val_loss: 1.3022 - val_accuracy: 0.6078\n",
      "Epoch 58/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 4s 29ms/step - loss: 0.5000 - accuracy: 0.8409 - val_loss: 1.2769 - val_accuracy: 0.6131\n",
      "Epoch 59/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.5000 - accuracy: 0.8383 - val_loss: 1.3147 - val_accuracy: 0.6092\n",
      "Epoch 60/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.4701 - accuracy: 0.8503 - val_loss: 1.3585 - val_accuracy: 0.6197\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9248)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1183872   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 120)               15480     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,234,680\n",
      "Trainable params: 1,234,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test loss: 1.3584903478622437\n",
      "Test accuracy: 0.6197222471237183\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:23:57.741143: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n",
      "2022-11-25 16:23:58.238718: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common sense accurasy\n",
      "train MAE = 0.05854861111111112\n",
      "in minutes = 3.5129166666666674\n",
      "test MAE = 0.596824074074074\n",
      "in minutes = 35.80944444444444\n"
     ]
    }
   ],
   "source": [
    "classification_time(120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 240 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:26:20.551656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:26:20.552164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:26:20.552414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:26:20.553055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:26:20.553225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:26:20.553414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:26:20.553594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:26:20.553714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:26:20.553806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6147 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2022-11-25 16:26:20.723260: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n",
      "2022-11-25 16:26:21.252553: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:26:23.010797: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "2022-11-25 16:26:23.646283: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 16:26:23.646565: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 16:26:23.646576: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-11-25 16:26:23.646906: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 16:26:23.646939: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-11-25 16:26:24.293108: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 7s 31ms/step - loss: 5.4845 - accuracy: 0.0024 - val_loss: 5.4824 - val_accuracy: 0.0036\n",
      "Epoch 2/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 5.4814 - accuracy: 0.0037 - val_loss: 5.4832 - val_accuracy: 0.0019\n",
      "Epoch 3/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 5.4812 - accuracy: 0.0035 - val_loss: 5.4842 - val_accuracy: 0.0019\n",
      "Epoch 4/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 5.4809 - accuracy: 0.0035 - val_loss: 5.4851 - val_accuracy: 0.0019\n",
      "Epoch 5/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 5.4746 - accuracy: 0.0060 - val_loss: 5.4622 - val_accuracy: 0.0033\n",
      "Epoch 6/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 5.2946 - accuracy: 0.0112 - val_loss: 5.0665 - val_accuracy: 0.0164\n",
      "Epoch 7/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 4.7564 - accuracy: 0.0319 - val_loss: 4.4765 - val_accuracy: 0.0425\n",
      "Epoch 8/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 4.3339 - accuracy: 0.0540 - val_loss: 4.0263 - val_accuracy: 0.0689\n",
      "Epoch 9/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 3.9930 - accuracy: 0.0780 - val_loss: 3.6829 - val_accuracy: 0.0967\n",
      "Epoch 10/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 3.7129 - accuracy: 0.1012 - val_loss: 3.4113 - val_accuracy: 0.1331\n",
      "Epoch 11/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 3.4628 - accuracy: 0.1238 - val_loss: 3.1898 - val_accuracy: 0.1508\n",
      "Epoch 12/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 3.2458 - accuracy: 0.1513 - val_loss: 3.0444 - val_accuracy: 0.1803\n",
      "Epoch 13/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 3.0545 - accuracy: 0.1705 - val_loss: 2.8576 - val_accuracy: 0.2019\n",
      "Epoch 14/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.8776 - accuracy: 0.1935 - val_loss: 2.5829 - val_accuracy: 0.2522\n",
      "Epoch 15/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.7277 - accuracy: 0.2242 - val_loss: 2.6248 - val_accuracy: 0.2206\n",
      "Epoch 16/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.5924 - accuracy: 0.2429 - val_loss: 2.7039 - val_accuracy: 0.2261\n",
      "Epoch 17/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.4627 - accuracy: 0.2714 - val_loss: 2.2275 - val_accuracy: 0.3119\n",
      "Epoch 18/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.3628 - accuracy: 0.2900 - val_loss: 2.2025 - val_accuracy: 0.3014\n",
      "Epoch 19/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.2562 - accuracy: 0.3126 - val_loss: 2.1144 - val_accuracy: 0.3269\n",
      "Epoch 20/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.1533 - accuracy: 0.3322 - val_loss: 1.9831 - val_accuracy: 0.3561\n",
      "Epoch 21/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.0751 - accuracy: 0.3517 - val_loss: 1.9396 - val_accuracy: 0.3578\n",
      "Epoch 22/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.9910 - accuracy: 0.3724 - val_loss: 1.9203 - val_accuracy: 0.3694\n",
      "Epoch 23/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.9048 - accuracy: 0.3971 - val_loss: 1.8421 - val_accuracy: 0.3947\n",
      "Epoch 24/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.8335 - accuracy: 0.4075 - val_loss: 1.8166 - val_accuracy: 0.3997\n",
      "Epoch 25/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.7605 - accuracy: 0.4305 - val_loss: 1.8754 - val_accuracy: 0.3736\n",
      "Epoch 26/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.7101 - accuracy: 0.4502 - val_loss: 1.7657 - val_accuracy: 0.4133\n",
      "Epoch 27/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.6400 - accuracy: 0.4668 - val_loss: 1.7277 - val_accuracy: 0.4208\n",
      "Epoch 28/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.5680 - accuracy: 0.4873 - val_loss: 1.8315 - val_accuracy: 0.3958\n",
      "Epoch 29/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.5123 - accuracy: 0.5022 - val_loss: 1.7487 - val_accuracy: 0.4164\n",
      "Epoch 30/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.4715 - accuracy: 0.5196 - val_loss: 1.6873 - val_accuracy: 0.4286\n",
      "Epoch 31/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.4115 - accuracy: 0.5360 - val_loss: 1.6882 - val_accuracy: 0.4311\n",
      "Epoch 32/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.3597 - accuracy: 0.5547 - val_loss: 1.6015 - val_accuracy: 0.4572\n",
      "Epoch 33/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.2949 - accuracy: 0.5762 - val_loss: 1.5977 - val_accuracy: 0.4600\n",
      "Epoch 34/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.2627 - accuracy: 0.5860 - val_loss: 1.5881 - val_accuracy: 0.4639\n",
      "Epoch 35/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.2342 - accuracy: 0.5888 - val_loss: 1.5994 - val_accuracy: 0.4728\n",
      "Epoch 36/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.1852 - accuracy: 0.6089 - val_loss: 1.6435 - val_accuracy: 0.4650\n",
      "Epoch 37/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.1586 - accuracy: 0.6205 - val_loss: 1.6136 - val_accuracy: 0.4683\n",
      "Epoch 38/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.1083 - accuracy: 0.6372 - val_loss: 1.6073 - val_accuracy: 0.4675\n",
      "Epoch 39/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.0861 - accuracy: 0.6499 - val_loss: 1.6429 - val_accuracy: 0.4694\n",
      "Epoch 40/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.0355 - accuracy: 0.6607 - val_loss: 1.6594 - val_accuracy: 0.4653\n",
      "Epoch 41/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.0129 - accuracy: 0.6703 - val_loss: 1.7660 - val_accuracy: 0.4381\n",
      "Epoch 42/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.9754 - accuracy: 0.6804 - val_loss: 1.6483 - val_accuracy: 0.4611\n",
      "Epoch 43/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.9395 - accuracy: 0.6956 - val_loss: 1.6831 - val_accuracy: 0.4653\n",
      "Epoch 44/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.9059 - accuracy: 0.7022 - val_loss: 1.7492 - val_accuracy: 0.4611\n",
      "Epoch 45/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.8873 - accuracy: 0.7163 - val_loss: 1.8983 - val_accuracy: 0.4414\n",
      "Epoch 46/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.8532 - accuracy: 0.7265 - val_loss: 1.7468 - val_accuracy: 0.4547\n",
      "Epoch 47/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.8375 - accuracy: 0.7285 - val_loss: 1.6948 - val_accuracy: 0.4622\n",
      "Epoch 48/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.8091 - accuracy: 0.7407 - val_loss: 1.6983 - val_accuracy: 0.4792\n",
      "Epoch 49/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.7681 - accuracy: 0.7556 - val_loss: 1.6974 - val_accuracy: 0.4706\n",
      "Epoch 50/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.7466 - accuracy: 0.7674 - val_loss: 1.7528 - val_accuracy: 0.4817\n",
      "Epoch 51/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.7431 - accuracy: 0.7636 - val_loss: 1.7527 - val_accuracy: 0.4731\n",
      "Epoch 52/60\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 0.6960 - accuracy: 0.7795 - val_loss: 1.9529 - val_accuracy: 0.4569\n",
      "Epoch 53/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.6907 - accuracy: 0.7851 - val_loss: 1.8580 - val_accuracy: 0.4722\n",
      "Epoch 54/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.6790 - accuracy: 0.7810 - val_loss: 1.8440 - val_accuracy: 0.4661\n",
      "Epoch 55/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.6631 - accuracy: 0.7862 - val_loss: 1.8993 - val_accuracy: 0.4586\n",
      "Epoch 56/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.6422 - accuracy: 0.7974 - val_loss: 1.9380 - val_accuracy: 0.4542\n",
      "Epoch 57/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.6389 - accuracy: 0.8003 - val_loss: 1.9374 - val_accuracy: 0.4561\n",
      "Epoch 58/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 4s 29ms/step - loss: 0.6125 - accuracy: 0.8072 - val_loss: 2.0090 - val_accuracy: 0.4625\n",
      "Epoch 59/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.6008 - accuracy: 0.8109 - val_loss: 1.9090 - val_accuracy: 0.4725\n",
      "Epoch 60/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.5798 - accuracy: 0.8177 - val_loss: 1.8750 - val_accuracy: 0.4758\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9248)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1183872   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 240)               30960     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,250,160\n",
      "Trainable params: 1,250,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test loss: 1.8750187158584595\n",
      "Test accuracy: 0.47611111402511597\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:30:34.676198: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n",
      "2022-11-25 16:30:35.234679: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common sense accurasy\n",
      "train MAE = 0.032940972222222226\n",
      "in minutes = 1.9764583333333334\n",
      "test MAE = 0.6858055555555554\n",
      "in minutes = 41.148333333333326\n"
     ]
    }
   ],
   "source": [
    "classification_time(240)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 480 classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:46:47.023360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:46:47.023670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:46:47.023876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:46:47.024375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:46:47.024581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:46:47.024757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:46:47.024964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:46:47.025130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:46:47.025253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6147 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2022-11-25 16:46:47.174286: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n",
      "2022-11-25 16:46:47.708808: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:46:49.182046: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "2022-11-25 16:46:49.834825: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 16:46:49.836714: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 16:46:49.836749: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-11-25 16:46:49.837815: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 16:46:49.837897: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-11-25 16:46:50.507370: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 7s 31ms/step - loss: 6.1608 - accuracy: 0.0024 - val_loss: 6.1476 - val_accuracy: 0.0019\n",
      "Epoch 2/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 6.1348 - accuracy: 0.0018 - val_loss: 6.1436 - val_accuracy: 0.0017\n",
      "Epoch 3/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 6.1296 - accuracy: 0.0020 - val_loss: 6.1412 - val_accuracy: 0.0017\n",
      "Epoch 4/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 6.1249 - accuracy: 0.0024 - val_loss: 6.1431 - val_accuracy: 8.3333e-04\n",
      "Epoch 5/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 6.1180 - accuracy: 0.0033 - val_loss: 6.1385 - val_accuracy: 5.5556e-04\n",
      "Epoch 6/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 6.0880 - accuracy: 0.0047 - val_loss: 6.1008 - val_accuracy: 0.0028\n",
      "Epoch 7/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 5.9291 - accuracy: 0.0094 - val_loss: 5.8611 - val_accuracy: 0.0111\n",
      "Epoch 8/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 5.5317 - accuracy: 0.0222 - val_loss: 5.3939 - val_accuracy: 0.0214\n",
      "Epoch 9/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 5.0632 - accuracy: 0.0369 - val_loss: 4.9124 - val_accuracy: 0.0361\n",
      "Epoch 10/60\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 4.6367 - accuracy: 0.0562 - val_loss: 4.5666 - val_accuracy: 0.0458\n",
      "Epoch 11/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 4.2826 - accuracy: 0.0779 - val_loss: 4.2493 - val_accuracy: 0.0719\n",
      "Epoch 12/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 4.0006 - accuracy: 0.0925 - val_loss: 3.9960 - val_accuracy: 0.0878\n",
      "Epoch 13/60\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 3.7613 - accuracy: 0.1203 - val_loss: 3.7981 - val_accuracy: 0.0969\n",
      "Epoch 14/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 3.5328 - accuracy: 0.1415 - val_loss: 3.5653 - val_accuracy: 0.1150\n",
      "Epoch 15/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 3.3279 - accuracy: 0.1655 - val_loss: 3.5396 - val_accuracy: 0.1264\n",
      "Epoch 16/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 3.1505 - accuracy: 0.1855 - val_loss: 3.2538 - val_accuracy: 0.1531\n",
      "Epoch 17/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.9812 - accuracy: 0.2116 - val_loss: 3.1693 - val_accuracy: 0.1681\n",
      "Epoch 18/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.8388 - accuracy: 0.2333 - val_loss: 3.1626 - val_accuracy: 0.1556\n",
      "Epoch 19/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.7070 - accuracy: 0.2589 - val_loss: 2.9895 - val_accuracy: 0.1742\n",
      "Epoch 20/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.6080 - accuracy: 0.2697 - val_loss: 2.9413 - val_accuracy: 0.1914\n",
      "Epoch 21/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.4693 - accuracy: 0.2963 - val_loss: 2.7901 - val_accuracy: 0.2172\n",
      "Epoch 22/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.3652 - accuracy: 0.3187 - val_loss: 2.8000 - val_accuracy: 0.2075\n",
      "Epoch 23/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.2776 - accuracy: 0.3386 - val_loss: 2.7342 - val_accuracy: 0.2217\n",
      "Epoch 24/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.1680 - accuracy: 0.3622 - val_loss: 2.7542 - val_accuracy: 0.2300\n",
      "Epoch 25/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.0925 - accuracy: 0.3756 - val_loss: 2.6567 - val_accuracy: 0.2336\n",
      "Epoch 26/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.0121 - accuracy: 0.3989 - val_loss: 2.6989 - val_accuracy: 0.2331\n",
      "Epoch 27/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.9463 - accuracy: 0.4226 - val_loss: 2.6538 - val_accuracy: 0.2436\n",
      "Epoch 28/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.8649 - accuracy: 0.4363 - val_loss: 2.7891 - val_accuracy: 0.2242\n",
      "Epoch 29/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.7915 - accuracy: 0.4580 - val_loss: 2.6398 - val_accuracy: 0.2422\n",
      "Epoch 30/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.7383 - accuracy: 0.4683 - val_loss: 2.7734 - val_accuracy: 0.2419\n",
      "Epoch 31/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.6588 - accuracy: 0.4931 - val_loss: 2.6719 - val_accuracy: 0.2447\n",
      "Epoch 32/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.5846 - accuracy: 0.5116 - val_loss: 2.7064 - val_accuracy: 0.2733\n",
      "Epoch 33/60\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 1.5162 - accuracy: 0.5307 - val_loss: 2.9053 - val_accuracy: 0.2494\n",
      "Epoch 34/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.4854 - accuracy: 0.5455 - val_loss: 2.7853 - val_accuracy: 0.2561\n",
      "Epoch 35/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.4463 - accuracy: 0.5541 - val_loss: 2.7775 - val_accuracy: 0.2517\n",
      "Epoch 36/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.3922 - accuracy: 0.5701 - val_loss: 2.7074 - val_accuracy: 0.2606\n",
      "Epoch 37/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.3387 - accuracy: 0.5865 - val_loss: 2.7716 - val_accuracy: 0.2611\n",
      "Epoch 38/60\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 1.3102 - accuracy: 0.5959 - val_loss: 2.7087 - val_accuracy: 0.2686\n",
      "Epoch 39/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.2317 - accuracy: 0.6205 - val_loss: 2.7823 - val_accuracy: 0.2553\n",
      "Epoch 40/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.2076 - accuracy: 0.6253 - val_loss: 2.9150 - val_accuracy: 0.2650\n",
      "Epoch 41/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.1585 - accuracy: 0.6464 - val_loss: 3.0031 - val_accuracy: 0.2603\n",
      "Epoch 42/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.1077 - accuracy: 0.6592 - val_loss: 3.0415 - val_accuracy: 0.2600\n",
      "Epoch 43/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.0848 - accuracy: 0.6654 - val_loss: 3.0697 - val_accuracy: 0.2547\n",
      "Epoch 44/60\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 1.0335 - accuracy: 0.6763 - val_loss: 3.0689 - val_accuracy: 0.2564\n",
      "Epoch 45/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.0020 - accuracy: 0.6924 - val_loss: 3.0312 - val_accuracy: 0.2753\n",
      "Epoch 46/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.9803 - accuracy: 0.7035 - val_loss: 3.1924 - val_accuracy: 0.2561\n",
      "Epoch 47/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.9436 - accuracy: 0.7145 - val_loss: 3.3724 - val_accuracy: 0.2478\n",
      "Epoch 48/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.9089 - accuracy: 0.7259 - val_loss: 3.3380 - val_accuracy: 0.2564\n",
      "Epoch 49/60\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 0.8964 - accuracy: 0.7247 - val_loss: 3.3750 - val_accuracy: 0.2600\n",
      "Epoch 50/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.8571 - accuracy: 0.7378 - val_loss: 3.2532 - val_accuracy: 0.2450\n",
      "Epoch 51/60\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 0.8334 - accuracy: 0.7443 - val_loss: 3.3551 - val_accuracy: 0.2506\n",
      "Epoch 52/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.8001 - accuracy: 0.7629 - val_loss: 3.4987 - val_accuracy: 0.2517\n",
      "Epoch 53/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.7859 - accuracy: 0.7603 - val_loss: 3.3300 - val_accuracy: 0.2514\n",
      "Epoch 54/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.7518 - accuracy: 0.7778 - val_loss: 3.4750 - val_accuracy: 0.2475\n",
      "Epoch 55/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.7540 - accuracy: 0.7746 - val_loss: 3.7391 - val_accuracy: 0.2492\n",
      "Epoch 56/60\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 0.7356 - accuracy: 0.7810 - val_loss: 3.6979 - val_accuracy: 0.2544\n",
      "Epoch 57/60\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 0.7046 - accuracy: 0.7894 - val_loss: 3.6474 - val_accuracy: 0.2522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/60\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 0.7086 - accuracy: 0.7899 - val_loss: 3.6338 - val_accuracy: 0.2531\n",
      "Epoch 59/60\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 0.6680 - accuracy: 0.7976 - val_loss: 3.9307 - val_accuracy: 0.2500\n",
      "Epoch 60/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.6655 - accuracy: 0.8030 - val_loss: 3.7794 - val_accuracy: 0.2486\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9248)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1183872   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 480)               61920     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,281,120\n",
      "Trainable params: 1,281,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test loss: 3.7793006896972656\n",
      "Test accuracy: 0.248055562376976\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:51:02.258946: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n",
      "2022-11-25 16:51:02.726984: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common sense accurasy\n",
      "train MAE = 0.02858275462962963\n",
      "in minutes = 1.714965277777778\n",
      "test MAE = 0.9390648148148147\n",
      "in minutes = 56.343888888888884\n"
     ]
    }
   ],
   "source": [
    "classification_time(480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 720 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:38:38.683980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:38:38.684342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:38:38.684597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:38:38.685241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:38:38.685505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:38:38.685745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:38:38.686080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:38:38.686351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 16:38:38.686529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6147 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2022-11-25 16:38:38.853159: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n",
      "2022-11-25 16:38:39.370236: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:38:40.923875: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "2022-11-25 16:38:41.599109: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 16:38:41.600308: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 16:38:41.600331: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-11-25 16:38:41.601078: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 16:38:41.601199: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-11-25 16:38:42.261741: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 7s 31ms/step - loss: 6.5801 - accuracy: 0.0019 - val_loss: 6.5797 - val_accuracy: 0.0031\n",
      "Epoch 2/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 6.5760 - accuracy: 0.0023 - val_loss: 6.5811 - val_accuracy: 0.0031\n",
      "Epoch 3/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 6.5707 - accuracy: 0.0031 - val_loss: 6.5836 - val_accuracy: 0.0017\n",
      "Epoch 4/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 6.5669 - accuracy: 0.0026 - val_loss: 6.5852 - val_accuracy: 0.0017\n",
      "Epoch 5/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 6.5644 - accuracy: 0.0017 - val_loss: 6.5950 - val_accuracy: 0.0022\n",
      "Epoch 6/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 6.5616 - accuracy: 0.0032 - val_loss: 6.5902 - val_accuracy: 0.0019\n",
      "Epoch 7/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 6.5466 - accuracy: 0.0040 - val_loss: 6.5802 - val_accuracy: 0.0039\n",
      "Epoch 8/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 6.4242 - accuracy: 0.0060 - val_loss: 6.3950 - val_accuracy: 0.0056\n",
      "Epoch 9/60\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 6.1437 - accuracy: 0.0067 - val_loss: 6.2497 - val_accuracy: 0.0078\n",
      "Epoch 10/60\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 5.8339 - accuracy: 0.0142 - val_loss: 5.9102 - val_accuracy: 0.0100\n",
      "Epoch 11/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 5.4939 - accuracy: 0.0220 - val_loss: 5.6298 - val_accuracy: 0.0125\n",
      "Epoch 12/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 5.1424 - accuracy: 0.0347 - val_loss: 5.4286 - val_accuracy: 0.0217\n",
      "Epoch 13/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 4.8230 - accuracy: 0.0513 - val_loss: 5.0855 - val_accuracy: 0.0314\n",
      "Epoch 14/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 4.5490 - accuracy: 0.0693 - val_loss: 4.8641 - val_accuracy: 0.0406\n",
      "Epoch 15/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 4.2908 - accuracy: 0.0894 - val_loss: 4.7533 - val_accuracy: 0.0439\n",
      "Epoch 16/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 4.0881 - accuracy: 0.1040 - val_loss: 4.5184 - val_accuracy: 0.0550\n",
      "Epoch 17/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 3.8831 - accuracy: 0.1171 - val_loss: 4.3510 - val_accuracy: 0.0653\n",
      "Epoch 18/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 3.6801 - accuracy: 0.1384 - val_loss: 4.3307 - val_accuracy: 0.0694\n",
      "Epoch 19/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 3.5147 - accuracy: 0.1594 - val_loss: 4.0907 - val_accuracy: 0.0792\n",
      "Epoch 20/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 3.3539 - accuracy: 0.1842 - val_loss: 4.1004 - val_accuracy: 0.0800\n",
      "Epoch 21/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 3.1923 - accuracy: 0.1982 - val_loss: 3.9851 - val_accuracy: 0.0914\n",
      "Epoch 22/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 3.0703 - accuracy: 0.2174 - val_loss: 3.9050 - val_accuracy: 0.0900\n",
      "Epoch 23/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.9431 - accuracy: 0.2403 - val_loss: 3.8970 - val_accuracy: 0.0958\n",
      "Epoch 24/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.8153 - accuracy: 0.2565 - val_loss: 3.7977 - val_accuracy: 0.1028\n",
      "Epoch 25/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.7221 - accuracy: 0.2713 - val_loss: 3.7782 - val_accuracy: 0.1094\n",
      "Epoch 26/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.5969 - accuracy: 0.2996 - val_loss: 3.7077 - val_accuracy: 0.1233\n",
      "Epoch 27/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.4941 - accuracy: 0.3214 - val_loss: 3.7740 - val_accuracy: 0.1147\n",
      "Epoch 28/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.3912 - accuracy: 0.3467 - val_loss: 3.7856 - val_accuracy: 0.1231\n",
      "Epoch 29/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 2.3028 - accuracy: 0.3603 - val_loss: 3.8665 - val_accuracy: 0.1128\n",
      "Epoch 30/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.2169 - accuracy: 0.3824 - val_loss: 3.8686 - val_accuracy: 0.1139\n",
      "Epoch 31/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.1199 - accuracy: 0.4015 - val_loss: 3.9300 - val_accuracy: 0.1236\n",
      "Epoch 32/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 2.0569 - accuracy: 0.4178 - val_loss: 4.1409 - val_accuracy: 0.1164\n",
      "Epoch 33/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.9584 - accuracy: 0.4392 - val_loss: 3.9614 - val_accuracy: 0.1294\n",
      "Epoch 34/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.8835 - accuracy: 0.4578 - val_loss: 4.1347 - val_accuracy: 0.1161\n",
      "Epoch 35/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.8190 - accuracy: 0.4748 - val_loss: 3.9633 - val_accuracy: 0.1261\n",
      "Epoch 36/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.7397 - accuracy: 0.4967 - val_loss: 4.5175 - val_accuracy: 0.1231\n",
      "Epoch 37/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.6664 - accuracy: 0.5192 - val_loss: 4.1033 - val_accuracy: 0.1356\n",
      "Epoch 38/60\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 1.6074 - accuracy: 0.5355 - val_loss: 4.5041 - val_accuracy: 0.1208\n",
      "Epoch 39/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.5545 - accuracy: 0.5474 - val_loss: 4.2874 - val_accuracy: 0.1292\n",
      "Epoch 40/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.5054 - accuracy: 0.5644 - val_loss: 4.2853 - val_accuracy: 0.1331\n",
      "Epoch 41/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.4432 - accuracy: 0.5831 - val_loss: 4.3234 - val_accuracy: 0.1269\n",
      "Epoch 42/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.4012 - accuracy: 0.5978 - val_loss: 4.7181 - val_accuracy: 0.1272\n",
      "Epoch 43/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.3427 - accuracy: 0.6130 - val_loss: 4.6360 - val_accuracy: 0.1292\n",
      "Epoch 44/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.2741 - accuracy: 0.6232 - val_loss: 4.7187 - val_accuracy: 0.1333\n",
      "Epoch 45/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.2385 - accuracy: 0.6393 - val_loss: 4.8336 - val_accuracy: 0.1347\n",
      "Epoch 46/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.1853 - accuracy: 0.6528 - val_loss: 4.8030 - val_accuracy: 0.1194\n",
      "Epoch 47/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 1.1607 - accuracy: 0.6646 - val_loss: 4.9358 - val_accuracy: 0.1278\n",
      "Epoch 48/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.1202 - accuracy: 0.6782 - val_loss: 5.1874 - val_accuracy: 0.1206\n",
      "Epoch 49/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.0909 - accuracy: 0.6840 - val_loss: 5.2177 - val_accuracy: 0.1242\n",
      "Epoch 50/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 1.0451 - accuracy: 0.6985 - val_loss: 5.4802 - val_accuracy: 0.1150\n",
      "Epoch 51/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.9942 - accuracy: 0.7163 - val_loss: 5.7174 - val_accuracy: 0.1181\n",
      "Epoch 52/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.9782 - accuracy: 0.7208 - val_loss: 5.2731 - val_accuracy: 0.1217\n",
      "Epoch 53/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.9282 - accuracy: 0.7330 - val_loss: 5.4380 - val_accuracy: 0.1167\n",
      "Epoch 54/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.9306 - accuracy: 0.7372 - val_loss: 5.6705 - val_accuracy: 0.1153\n",
      "Epoch 55/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.8938 - accuracy: 0.7454 - val_loss: 5.7591 - val_accuracy: 0.1092\n",
      "Epoch 56/60\n",
      "144/144 [==============================] - 4s 28ms/step - loss: 0.8627 - accuracy: 0.7540 - val_loss: 5.3493 - val_accuracy: 0.1175\n",
      "Epoch 57/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.8362 - accuracy: 0.7585 - val_loss: 5.4966 - val_accuracy: 0.1164\n",
      "Epoch 58/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 4s 29ms/step - loss: 0.8213 - accuracy: 0.7648 - val_loss: 5.7054 - val_accuracy: 0.1211\n",
      "Epoch 59/60\n",
      "144/144 [==============================] - 4s 29ms/step - loss: 0.7993 - accuracy: 0.7741 - val_loss: 5.8486 - val_accuracy: 0.1211\n",
      "Epoch 60/60\n",
      "144/144 [==============================] - 4s 30ms/step - loss: 0.7910 - accuracy: 0.7803 - val_loss: 5.6871 - val_accuracy: 0.1192\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9248)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1183872   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 720)               92880     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,312,080\n",
      "Trainable params: 1,312,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test loss: 5.687101364135742\n",
      "Test accuracy: 0.11916666477918625\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:42:52.734004: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n",
      "2022-11-25 16:42:53.204418: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common sense accurasy\n",
      "train MAE = 0.0254965277777778\n",
      "in minutes = 1.529791666666668\n",
      "test MAE = 1.3897499999999998\n",
      "in minutes = 83.38499999999999\n"
     ]
    }
   ],
   "source": [
    "classification_time(720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-head models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Nl_QmA_X0KH",
    "outputId": "e5e9a3a0-c3a8-4697-b5f6-7f8dbe01e230"
   },
   "outputs": [],
   "source": [
    "# Multi-head classification\n",
    "mh_labels_min = labels[:, 1].astype(np.float32)/60.0\n",
    "mh_labels_hour = labels[:, 0].astype(np.int32)\n",
    "\n",
    "num_classes = 12\n",
    "\n",
    "'''mh_labels[:,0]=labels[:,0]\n",
    "for i in range(len(labels)):\n",
    "  mh_labels[i,1] = labels[i, 1].astype(np.float32)/60.0\n",
    "print(mh_labels[0:10])h'''\n",
    "\n",
    "y_train_hours = keras.utils.to_categorical(mh_labels_hour[:split_idx], num_classes)\n",
    "y_test_hours = keras.utils.to_categorical(mh_labels_hour[split_idx:], num_classes)\n",
    "y_train_minutes = mh_labels_min[:split_idx]\n",
    "y_test_minutes = mh_labels_min[split_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the common sense accuracy for evaluating the accuracy after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FzAorCVUAVCG"
   },
   "outputs": [],
   "source": [
    "def MAELoss(y_true, y_pred):\n",
    "    y_true = np.array([y_true[0][i]+y_true[1][i] for i in range(len(y_true[0]))])\n",
    "    y_pred = np.array([np.argmax(y_pred[0][i])+y_pred[1][i][0] for i in range(len(y_pred[0]))])\n",
    "    res = np.abs(y_true - y_pred)\n",
    "    res2 = np.minimum(res, 12.0 - res)\n",
    "    return np.mean(res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kmuBdJWma0vS",
    "outputId": "f3ebdc90-0f27-4059-838c-2f19c3fda4d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 17:03:18.781958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 17:03:18.782154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 17:03:18.782282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 17:03:18.782780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 17:03:18.783387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 17:03:18.783502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 17:03:18.784430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 17:03:18.784709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-25 17:03:18.785053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6147 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:2d:00.0, compute capability: 8.6\n",
      "2022-11-25 17:03:18.955413: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n",
      "2022-11-25 17:03:19.454040: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 17:03:21.454063: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "2022-11-25 17:03:22.263328: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 17:03:22.264232: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 17:03:22.264291: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-11-25 17:03:22.264875: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-25 17:03:22.264918: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-11-25 17:03:23.027367: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 7s 26ms/step - loss: 2.8159 - hours_out_loss: 2.4896 - minutes_out_loss: 0.1416 - val_loss: 2.5856 - val_hours_out_loss: 2.4868 - val_minutes_out_loss: 0.0912\n",
      "Epoch 2/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 2.5783 - hours_out_loss: 2.4854 - minutes_out_loss: 0.0847 - val_loss: 2.5674 - val_hours_out_loss: 2.4865 - val_minutes_out_loss: 0.0723\n",
      "Epoch 3/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 2.5644 - hours_out_loss: 2.4719 - minutes_out_loss: 0.0716 - val_loss: 2.5297 - val_hours_out_loss: 2.4149 - val_minutes_out_loss: 0.0649\n",
      "Epoch 4/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 2.4740 - hours_out_loss: 2.3257 - minutes_out_loss: 0.0634 - val_loss: 2.3353 - val_hours_out_loss: 2.1675 - val_minutes_out_loss: 0.0569\n",
      "Epoch 5/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 2.2845 - hours_out_loss: 2.0997 - minutes_out_loss: 0.0582 - val_loss: 2.1660 - val_hours_out_loss: 1.9713 - val_minutes_out_loss: 0.0608\n",
      "Epoch 6/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 2.1228 - hours_out_loss: 1.9279 - minutes_out_loss: 0.0525 - val_loss: 2.0450 - val_hours_out_loss: 1.8400 - val_minutes_out_loss: 0.0497\n",
      "Epoch 7/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 1.9859 - hours_out_loss: 1.7769 - minutes_out_loss: 0.0487 - val_loss: 1.8937 - val_hours_out_loss: 1.6804 - val_minutes_out_loss: 0.0480\n",
      "Epoch 8/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 1.8587 - hours_out_loss: 1.6403 - minutes_out_loss: 0.0452 - val_loss: 1.7206 - val_hours_out_loss: 1.4914 - val_minutes_out_loss: 0.0480\n",
      "Epoch 9/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 1.7467 - hours_out_loss: 1.5190 - minutes_out_loss: 0.0415 - val_loss: 1.6297 - val_hours_out_loss: 1.3914 - val_minutes_out_loss: 0.0483\n",
      "Epoch 10/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 1.6567 - hours_out_loss: 1.4208 - minutes_out_loss: 0.0386 - val_loss: 1.5496 - val_hours_out_loss: 1.3015 - val_minutes_out_loss: 0.0461\n",
      "Epoch 11/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 1.5629 - hours_out_loss: 1.3206 - minutes_out_loss: 0.0349 - val_loss: 1.5052 - val_hours_out_loss: 1.2494 - val_minutes_out_loss: 0.0487\n",
      "Epoch 12/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 1.4693 - hours_out_loss: 1.2195 - minutes_out_loss: 0.0324 - val_loss: 1.3329 - val_hours_out_loss: 1.0720 - val_minutes_out_loss: 0.0428\n",
      "Epoch 13/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 1.4035 - hours_out_loss: 1.1486 - minutes_out_loss: 0.0288 - val_loss: 1.3261 - val_hours_out_loss: 1.0615 - val_minutes_out_loss: 0.0361\n",
      "Epoch 14/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 1.3472 - hours_out_loss: 1.0870 - minutes_out_loss: 0.0262 - val_loss: 1.2893 - val_hours_out_loss: 1.0113 - val_minutes_out_loss: 0.0400\n",
      "Epoch 15/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 1.2836 - hours_out_loss: 1.0172 - minutes_out_loss: 0.0236 - val_loss: 1.4009 - val_hours_out_loss: 1.1222 - val_minutes_out_loss: 0.0344\n",
      "Epoch 16/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 1.2450 - hours_out_loss: 0.9752 - minutes_out_loss: 0.0212 - val_loss: 1.1629 - val_hours_out_loss: 0.8777 - val_minutes_out_loss: 0.0356\n",
      "Epoch 17/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 1.1959 - hours_out_loss: 0.9229 - minutes_out_loss: 0.0192 - val_loss: 1.1636 - val_hours_out_loss: 0.8748 - val_minutes_out_loss: 0.0361\n",
      "Epoch 18/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 1.1497 - hours_out_loss: 0.8743 - minutes_out_loss: 0.0169 - val_loss: 1.1872 - val_hours_out_loss: 0.8940 - val_minutes_out_loss: 0.0314\n",
      "Epoch 19/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 1.1178 - hours_out_loss: 0.8386 - minutes_out_loss: 0.0157 - val_loss: 1.0549 - val_hours_out_loss: 0.7623 - val_minutes_out_loss: 0.0301\n",
      "Epoch 20/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 1.0852 - hours_out_loss: 0.8029 - minutes_out_loss: 0.0143 - val_loss: 1.1907 - val_hours_out_loss: 0.8869 - val_minutes_out_loss: 0.0344\n",
      "Epoch 21/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 1.0466 - hours_out_loss: 0.7620 - minutes_out_loss: 0.0132 - val_loss: 1.0207 - val_hours_out_loss: 0.7178 - val_minutes_out_loss: 0.0303\n",
      "Epoch 22/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 1.0067 - hours_out_loss: 0.7193 - minutes_out_loss: 0.0119 - val_loss: 1.0557 - val_hours_out_loss: 0.7488 - val_minutes_out_loss: 0.0290\n",
      "Epoch 23/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.9876 - hours_out_loss: 0.6993 - minutes_out_loss: 0.0112 - val_loss: 0.9901 - val_hours_out_loss: 0.6848 - val_minutes_out_loss: 0.0287\n",
      "Epoch 24/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.9561 - hours_out_loss: 0.6672 - minutes_out_loss: 0.0104 - val_loss: 1.0040 - val_hours_out_loss: 0.6940 - val_minutes_out_loss: 0.0290\n",
      "Epoch 25/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.9267 - hours_out_loss: 0.6373 - minutes_out_loss: 0.0095 - val_loss: 0.9557 - val_hours_out_loss: 0.6456 - val_minutes_out_loss: 0.0302\n",
      "Epoch 26/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.9073 - hours_out_loss: 0.6175 - minutes_out_loss: 0.0086 - val_loss: 0.9284 - val_hours_out_loss: 0.6200 - val_minutes_out_loss: 0.0268\n",
      "Epoch 27/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.8776 - hours_out_loss: 0.5860 - minutes_out_loss: 0.0080 - val_loss: 0.9340 - val_hours_out_loss: 0.6258 - val_minutes_out_loss: 0.0265\n",
      "Epoch 28/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.8548 - hours_out_loss: 0.5645 - minutes_out_loss: 0.0076 - val_loss: 1.0286 - val_hours_out_loss: 0.7122 - val_minutes_out_loss: 0.0306\n",
      "Epoch 29/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.8347 - hours_out_loss: 0.5449 - minutes_out_loss: 0.0073 - val_loss: 0.8322 - val_hours_out_loss: 0.5246 - val_minutes_out_loss: 0.0272\n",
      "Epoch 30/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.8144 - hours_out_loss: 0.5257 - minutes_out_loss: 0.0068 - val_loss: 0.8831 - val_hours_out_loss: 0.5758 - val_minutes_out_loss: 0.0280\n",
      "Epoch 31/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.7983 - hours_out_loss: 0.5116 - minutes_out_loss: 0.0065 - val_loss: 0.8350 - val_hours_out_loss: 0.5264 - val_minutes_out_loss: 0.0282\n",
      "Epoch 32/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.7790 - hours_out_loss: 0.4918 - minutes_out_loss: 0.0063 - val_loss: 0.8369 - val_hours_out_loss: 0.5270 - val_minutes_out_loss: 0.0283\n",
      "Epoch 33/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.7652 - hours_out_loss: 0.4799 - minutes_out_loss: 0.0057 - val_loss: 0.8197 - val_hours_out_loss: 0.5149 - val_minutes_out_loss: 0.0280\n",
      "Epoch 34/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.7479 - hours_out_loss: 0.4643 - minutes_out_loss: 0.0054 - val_loss: 0.7603 - val_hours_out_loss: 0.4585 - val_minutes_out_loss: 0.0245\n",
      "Epoch 35/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.7450 - hours_out_loss: 0.4629 - minutes_out_loss: 0.0053 - val_loss: 0.7946 - val_hours_out_loss: 0.4929 - val_minutes_out_loss: 0.0264\n",
      "Epoch 36/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.7159 - hours_out_loss: 0.4364 - minutes_out_loss: 0.0049 - val_loss: 0.8189 - val_hours_out_loss: 0.5212 - val_minutes_out_loss: 0.0253\n",
      "Epoch 37/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.7070 - hours_out_loss: 0.4285 - minutes_out_loss: 0.0047 - val_loss: 0.7470 - val_hours_out_loss: 0.4472 - val_minutes_out_loss: 0.0248\n",
      "Epoch 38/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.6955 - hours_out_loss: 0.4167 - minutes_out_loss: 0.0045 - val_loss: 0.7608 - val_hours_out_loss: 0.4621 - val_minutes_out_loss: 0.0247\n",
      "Epoch 39/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.6801 - hours_out_loss: 0.4043 - minutes_out_loss: 0.0044 - val_loss: 0.7238 - val_hours_out_loss: 0.4266 - val_minutes_out_loss: 0.0240\n",
      "Epoch 40/60\n",
      "144/144 [==============================] - 3s 24ms/step - loss: 0.6718 - hours_out_loss: 0.3952 - minutes_out_loss: 0.0041 - val_loss: 0.7085 - val_hours_out_loss: 0.4139 - val_minutes_out_loss: 0.0236\n",
      "Epoch 41/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.6598 - hours_out_loss: 0.3864 - minutes_out_loss: 0.0040 - val_loss: 0.7402 - val_hours_out_loss: 0.4437 - val_minutes_out_loss: 0.0252\n",
      "Epoch 42/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.6526 - hours_out_loss: 0.3794 - minutes_out_loss: 0.0038 - val_loss: 0.7667 - val_hours_out_loss: 0.4726 - val_minutes_out_loss: 0.0258\n",
      "Epoch 43/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.6430 - hours_out_loss: 0.3721 - minutes_out_loss: 0.0038 - val_loss: 0.7071 - val_hours_out_loss: 0.4193 - val_minutes_out_loss: 0.0224\n",
      "Epoch 44/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.6333 - hours_out_loss: 0.3654 - minutes_out_loss: 0.0037 - val_loss: 0.6762 - val_hours_out_loss: 0.3907 - val_minutes_out_loss: 0.0220\n",
      "Epoch 45/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.6234 - hours_out_loss: 0.3572 - minutes_out_loss: 0.0036 - val_loss: 0.6935 - val_hours_out_loss: 0.4037 - val_minutes_out_loss: 0.0236\n",
      "Epoch 46/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.6242 - hours_out_loss: 0.3586 - minutes_out_loss: 0.0034 - val_loss: 0.6767 - val_hours_out_loss: 0.3912 - val_minutes_out_loss: 0.0238\n",
      "Epoch 47/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.6119 - hours_out_loss: 0.3477 - minutes_out_loss: 0.0032 - val_loss: 0.6764 - val_hours_out_loss: 0.3916 - val_minutes_out_loss: 0.0226\n",
      "Epoch 48/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5979 - hours_out_loss: 0.3361 - minutes_out_loss: 0.0031 - val_loss: 0.6808 - val_hours_out_loss: 0.4014 - val_minutes_out_loss: 0.0225\n",
      "Epoch 49/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.5894 - hours_out_loss: 0.3288 - minutes_out_loss: 0.0031 - val_loss: 0.6838 - val_hours_out_loss: 0.3988 - val_minutes_out_loss: 0.0236\n",
      "Epoch 50/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5858 - hours_out_loss: 0.3242 - minutes_out_loss: 0.0029 - val_loss: 0.6249 - val_hours_out_loss: 0.3425 - val_minutes_out_loss: 0.0228\n",
      "Epoch 51/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5879 - hours_out_loss: 0.3293 - minutes_out_loss: 0.0029 - val_loss: 0.6490 - val_hours_out_loss: 0.3710 - val_minutes_out_loss: 0.0227\n",
      "Epoch 52/60\n",
      "144/144 [==============================] - 3s 23ms/step - loss: 0.5728 - hours_out_loss: 0.3167 - minutes_out_loss: 0.0028 - val_loss: 0.6666 - val_hours_out_loss: 0.3868 - val_minutes_out_loss: 0.0253\n",
      "Epoch 53/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5746 - hours_out_loss: 0.3171 - minutes_out_loss: 0.0027 - val_loss: 0.6949 - val_hours_out_loss: 0.4146 - val_minutes_out_loss: 0.0231\n",
      "Epoch 54/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5647 - hours_out_loss: 0.3088 - minutes_out_loss: 0.0025 - val_loss: 0.6350 - val_hours_out_loss: 0.3577 - val_minutes_out_loss: 0.0243\n",
      "Epoch 55/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5584 - hours_out_loss: 0.3046 - minutes_out_loss: 0.0026 - val_loss: 0.6822 - val_hours_out_loss: 0.4062 - val_minutes_out_loss: 0.0249\n",
      "Epoch 56/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5522 - hours_out_loss: 0.2987 - minutes_out_loss: 0.0025 - val_loss: 0.6182 - val_hours_out_loss: 0.3425 - val_minutes_out_loss: 0.0234\n",
      "Epoch 57/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5549 - hours_out_loss: 0.3036 - minutes_out_loss: 0.0024 - val_loss: 0.6040 - val_hours_out_loss: 0.3326 - val_minutes_out_loss: 0.0222\n",
      "Epoch 58/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5443 - hours_out_loss: 0.2943 - minutes_out_loss: 0.0025 - val_loss: 0.6311 - val_hours_out_loss: 0.3606 - val_minutes_out_loss: 0.0230\n",
      "Epoch 59/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5491 - hours_out_loss: 0.2997 - minutes_out_loss: 0.0025 - val_loss: 0.5864 - val_hours_out_loss: 0.3161 - val_minutes_out_loss: 0.0220\n",
      "Epoch 60/60\n",
      "144/144 [==============================] - 3s 22ms/step - loss: 0.5311 - hours_out_loss: 0.2818 - minutes_out_loss: 0.0023 - val_loss: 0.5732 - val_hours_out_loss: 0.3003 - val_minutes_out_loss: 0.0231\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " clock_input (InputLayer)       [(None, 150, 150, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 148, 148, 16  160         ['clock_input[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 74, 74, 16)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 72, 72, 32)   4640        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 36, 36, 32)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 34, 34, 32)   9248        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 32)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 9248)         0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 256)          2367744     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          32896       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          1183872     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          16512       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " hours_out (Dense)              (None, 12)           1548        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " minutes_out (Dense)            (None, 1)            129         ['dense_1[0][0]']                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,616,749\n",
      "Trainable params: 3,616,749\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "113/113 [==============================] - 1s 5ms/step - loss: 0.5732 - hours_out_loss: 0.3003 - minutes_out_loss: 0.0231\n",
      "[0.5732386708259583, 0.3003292977809906, 0.023054003715515137]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_clock = Input(shape=(150, 150, 1), name=\"clock_input\")\n",
    "conv1 = Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 1))(input_clock)\n",
    "mp1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "conv2 = Conv2D(32, kernel_size=(3, 3), activation='relu')(mp1)\n",
    "mp2 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "conv3 = Conv2D(32, kernel_size=(3, 3), activation='relu')(mp2)\n",
    "mp3 = MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "flt = Flatten()(mp3)\n",
    "dns_min1 = Dense(128, activation='relu')(flt)\n",
    "dns_min2 = Dense(128, activation='relu')(dns_min1)\n",
    "minutes_out = Dense(1, activation='linear', name=\"minutes_out\")(dns_min2)\n",
    "\n",
    "dns_hr1 = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(l2=0.01))(flt)\n",
    "drp1 =  Dropout(0.1)(dns_hr1)\n",
    "dns_hr2 = Dense(128, activation='relu')(drp1)\n",
    "drp2 = Dropout(0.1)(dns_hr2)\n",
    "hours_out = Dense(num_classes, activation='softmax', name=\"hours_out\")(drp2)\n",
    "model=keras.Model(inputs=[input_clock], outputs=[hours_out, minutes_out])\n",
    "\n",
    "model.compile(loss=[keras.losses.categorical_crossentropy, tf.keras.losses.MeanSquaredError()], optimizer=keras.optimizers.RMSprop())\n",
    "\n",
    "model.fit(images[:split_idx], [y_train_hours, y_train_minutes],\n",
    "    batch_size=100,\n",
    "    epochs=60,\n",
    "    verbose=1,\n",
    "    validation_data=([images[split_idx:]],[y_test_hours, y_test_minutes]))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "score = model.evaluate(images[split_idx:], [y_test_hours, y_test_minutes])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OLZVAvHz9Zcl",
    "outputId": "1fd4ab58-0c31-4b65-9212-13fccd665f36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 17:06:39.526396: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n",
      "2022-11-25 17:06:40.045198: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1296000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy result for training:  0.08184992618082712\n",
      "in minutes:  4.910995570849627\n",
      "Accuracy result for testing:  0.19513574002103673\n",
      "in minutes:  11.708144401262203\n"
     ]
    }
   ],
   "source": [
    "# Check how well the model performed\n",
    "predictions=model.predict(images[:split_idx])\n",
    "print(\"Accuracy result for training: \",MAELoss([mh_labels_hour[:split_idx],mh_labels_min[:split_idx]], predictions))\n",
    "print(\"in minutes: \",MAELoss([mh_labels_hour[:split_idx],mh_labels_min[:split_idx]], predictions)*60)\n",
    "\n",
    "predictions=model.predict(images[split_idx:])\n",
    "print(\"Accuracy result for testing: \",MAELoss([mh_labels_hour[split_idx:],mh_labels_min[split_idx:]], predictions))\n",
    "print(\"in minutes: \",MAELoss([mh_labels_hour[split_idx:],mh_labels_min[split_idx:]], predictions)*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification plot for the report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= [24,48,120,240,480,720]\n",
    "train_mae = [14.6,7.1,3.5,2.0,1.7,1.5]\n",
    "test_mae  = [24.8,22.9,35.8,41.1,56.3,83.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(classes,train_mae,label='Training',color='red')\n",
    "plt.scatter(classes,train_mae,color='red')\n",
    "plt.plot(classes,test_mae,label='Testing')\n",
    "plt.scatter(classes,test_mae)\n",
    "plt.grid()\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('Number of classes',fontsize=20)\n",
    "plt.ylabel('Mean Absolute Error',fontsize=20)\n",
    "plt.savefig('classification.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
